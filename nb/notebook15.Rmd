---
title: "Notebook 15"
output:
  html_document:
    theme: cosmo
    highlight: zenburn
    css: "../css/note-style.css"
---

```{r, include=FALSE}
source("../funs/funs.R")
source("../funs/funs_custom.R")
```

## Parsing Wikipedia

In previous notes we have used the MediaWiki API to grab information about the
number of page views there have been in the past 60 days for each page
associated with a row in our `foods` dataset. The API also allows us to grab
data about the actual current content of any page on Wikipedia. Here is the
query string for accessing the page for "apple":

```{r}
url_str <- modify_url("https://en.wikipedia.org/w/api.php",
                       query = list(action = "parse", format = "json", page = "apple"))

res <- dsst_cache_get(url_str, cache_dir = "cache")
obj <- content(res, type = "application/json")
```

Calling the query string yields a JSON object that contains some metadata about
the page contents. It also contains a text representation of the page parsed
into HTML. In summary, the JSON file contains an element that is in HTML (!).
Here is the a sample of the HTML file:

```{r}
html_txt <- obj$parse$text[["*"]]
stri_wrap(stri_sub(html_txt, 1, 1000), 70)
```

Now, we can use the `read_html` function to convert the text into an
`html_document`.

```{r}
obj_html <- read_html(html_txt)
obj_html
```

The larger JSON object contains a set of all links that are found on the page,
but it does not tell us where they occur in the page. This can be a problem
because it includes lots of extra links found at the top and bottom on the page.
To get a more accurate sense of the links within the body of the text, we need
to grab them from the parsed HTML.

In the code below, extract all of the links (the "a" tag) that are somewhere 
inside the paragraph tags ("p") of the Wikipedia text.

```{r, question-01}

```

Now, create a data table that has three columns: `item` (which is always equal to
"Apple"), `link` giving the href url within each of the links found above, and
`text` giving the text inside the links above. Name the dataset `wiki_links`

```{r, question-02}

```

Some of the links you found above may be to external pages or to footnotes. 
Filter the `wiki_links` to include only those that start with "/wiki/" and 
then remove the leading "/wiki/" from the remaining links. Resave the data 
as `wiki_links`.

```{r, question-03}

```

Now, without saving the output, look at the items in `wiki_links` where a
lowercase version of the link does not each a lowercase version of the text.
What differences do you see?

```{r, question-04}

```

Now, create a summarized version of `wiki_links` that has one row for each
unique link, with a count column. Arrange the links from the highest to the
lowest number. You don't need the text column here.

```{r, question-05}

```


