---
title: "10. EDA"
output:
  html_document:
    theme: cosmo
    highlight: zenburn
    css: "../css/note-style.css"
---

```{r, message=FALSE, echo=FALSE}
source("../funs/funs.R")
options(dsst.traceit = FALSE)
```

## Load the Data

For today's notes we will work with one of the data sets from Project 2,
specifically the reviews of Music CDs.

```{r, message=FALSE}
docs <- read_csv("../data/amazon_cds.csv.bz2")
anno <- read_csv("../data/amazon_cds_token.csv.bz2")
```

We are going to briefly redescribe the two clutsering algorithms from last time
and show how they can be used in data analysis.

## Working with the Clusters

I wanted to show a few things you can do with the cluster assignments. In
general, I use them as artificially constructed labels for the documents.

```{r}
df <- anno %>%
  filter(upos %in% c("NOUN", "VERB")) %>%
  inner_join(select(docs, -text), by = "doc_id") %>%
  dsst_pca(doc_var = "label", n_dims = 2) %>%
  dsst_kmeans(n_clusters = 5L)
```


For example, we can see the average length of each cluster's documents:

```{r}
anno %>%
  group_by(doc_id) %>%
  summarise(n = n()) %>%
  left_join(docs, by = "doc_id") %>%
  left_join(df, by = "label") %>%
  group_by(cluster) %>%
  summarise(avg_tokens = mean(n)) %>%
  ggplot(aes(factor(cluster), avg_tokens)) +
    geom_col(aes(fill = factor(cluster)), show.legend = FALSE) +
    labs(x = "Cluster", y = "Average Number of Tokens per Review")
```

Or compute the G-score metrics:

```{r}
anno %>%
  filter(upos %in% c("NOUN", "VERB")) %>%
  dsst_metrics(left_join(docs, df, by = "label"), label_var = "cluster")
```

Or even build a predictive model:

```{r}
model <- anno %>%
  filter(upos %in% c("NOUN", "VERB")) %>%
  dsst_enet_build(left_join(docs, df, by = "label"),
                  label_var = "cluster")

model$docs %>%
  group_by(train_id) %>%
  summarize(erate = mean(cluster != pred_label))
```

Does the confusion matrix show a similar structure to that of the heirarchical
clustering?

```{r}
model$docs %>%
  select(cluster, pred_label, train_id) %>%
  table()
```

You can even do the clustering on all of the documents and analyse those.

```{r}
df <- anno %>%
  dsst_pca(n_dims = 2L) %>%
  dsst_kmeans(n_clusters = 20L)
```

Do the clusters of the documents correspond to particular users?

```{r}
df %>%
  left_join(docs, by = "doc_id") %>%
  select(cluster, label) %>%
  table()
```

And are there any patterns related to the length of each of the clusters?

```{r}
anno %>%
  group_by(doc_id) %>%
  summarise(n = n()) %>%
  left_join(df, by = "doc_id") %>%
  group_by(cluster) %>%
  summarise(avg_tokens = mean(n)) %>%
  ggplot(aes(factor(cluster), avg_tokens)) +
    geom_col(aes(fill = factor(cluster)), show.legend = FALSE) +
    labs(x = "Cluster", y = "Average Number of Tokens per Review")
```
